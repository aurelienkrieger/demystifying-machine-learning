# Session 2

1. Discussion about readings


2. Study on workflow
  - drawing of workflow
  - demos:
    - combining models: [Cassify rock paper scissors ml5.js](https://editor.p5js.org/tlsaeger/sketches/xL2DrkcEb)
    - regression:
      - [Musical mouse](https://editor.p5js.org/ml5/sketches/NeuralNetwork_musical_mouse)
      - [Feature extractor image regresssion](https://editor.p5js.org/ml5/sketches/FeatureExtractor_Image_Regression)
    - chaining tools: [FaceOSC > Wekinator > Processing](https://vimeo.com/175947130)
    - chaingin tools: [no-kinect > TiouchDesigner](https://www.youtube.com/watch?v=DpGHWa2gOcc)
  - discussion: inputs/outputs (Arduino, MaxMSP / Pure Data, ...)


3. Prototyping - Open workflow
  - use p5.FaceOSC to send facial keypoints to Processing & Wekinator
  - train classifier to trigger sounds
  - train regression model to control oscillator

4. Prototyping - Game controller
  - control game with sound classifier

5. Introduction to Machine Learning for Text
  - basic concepts & categories of models
  - [MediaPipe demos](https://mediapipe-studio.webapps.google.com/home)
  - inspirations: text

6. Prototyping - Text
  - predict the sentiment of a text with Sentiment + ml5
  - program chatbot with chatGPT
